{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedBaari/Deep-Learning-Essentials/blob/main/11%20-%20GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6Xp_BV9UMjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ou4ZymPH6vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4387f8-af90-4493-d13b-8bf92936663b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Saving images to folder...\n",
            "Saved 60000 images to 'mnist_data' folder!\n"
          ]
        }
      ],
      "source": [
        "# ===== PART 1: DOWNLOAD & SAVE MNIST TO FOLDER =====\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "def save_mnist_to_folder(folder='mnist_data'):\n",
        "    # Download MNIST\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Create folder structure: mnist_data/0/, mnist_data/1/, etc.\n",
        "    for digit in range(10):\n",
        "        os.makedirs(f'{folder}/{digit}', exist_ok=True)\n",
        "\n",
        "    # Save training images\n",
        "    print(\"Saving images to folder...\")\n",
        "    for i, (img, label) in enumerate(zip(x_train, y_train)):\n",
        "        img_path = f'{folder}/{label}/train_{i}.png'\n",
        "        Image.fromarray(img).save(img_path)\n",
        "\n",
        "    print(f\"Saved {len(x_train)} images to '{folder}' folder!\")\n",
        "    return folder\n",
        "\n",
        "# Execute: Save and Load\n",
        "folder_name = 'mnist_data'\n",
        "if not os.path.exists(folder_name):\n",
        "    save_mnist_to_folder(folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAAKfzLaHtx3",
        "outputId": "e2facdb3-e6db-4bd4-e09b-45af2994d706"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 60000 files.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        }
      ],
      "source": [
        "# ULTRA-MINIMAL GAN - EASIEST TO MEMORIZE\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, Input, Reshape\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# 1. LOAD DATA using image_dataset_from_directory\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = (image - 0.5) / 0.5 # Scale to [-1, 1]\n",
        "    return image\n",
        "\n",
        "batch_size = 128\n",
        "image_size = (28, 28)\n",
        "data_dir = 'mnist_data'\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode=None, # We don't need labels for GAN training\n",
        "    image_size=image_size,\n",
        "    color_mode='grayscale', # Load images in grayscale\n",
        "    interpolation='nearest',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "train_ds = train_ds.map(preprocess_image)\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# 2. BUILD GENERATOR\n",
        "def make_generator():\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=100),\n",
        "        LeakyReLU(0.2),\n",
        "        Dense(784, activation='tanh'),\n",
        "        Reshape((28, 28, 1)) # Reshape output to image format\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 3. BUILD DISCRIMINATOR\n",
        "def make_discriminator():\n",
        "    model = Sequential([\n",
        "        Reshape((784,), input_shape=(28, 28, 1)), # Flatten the input image\n",
        "        Dense(128, input_dim=784),\n",
        "        LeakyReLU(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 4. CREATE MODELS\n",
        "D = make_discriminator()\n",
        "D.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "G = make_generator()\n",
        "D.trainable = False\n",
        "GAN = Sequential([G, D])\n",
        "GAN.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# 5. TRAIN\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    for image_batch in train_ds:\n",
        "        current_batch_size = tf.shape(image_batch)[0] # Get the actual batch size\n",
        "\n",
        "        # Train Discriminator\n",
        "        real = image_batch\n",
        "        fake = G.predict(tf.random.normal([current_batch_size, 100]), verbose=0)\n",
        "\n",
        "        D.train_on_batch(real, tf.ones((current_batch_size, 1)))\n",
        "        D.train_on_batch(fake, tf.zeros((current_batch_size, 1)))\n",
        "\n",
        "        # Train Generator\n",
        "        GAN.train_on_batch(tf.random.normal([current_batch_size, 100]), tf.ones((current_batch_size, 1)))\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f'Epoch {epoch}')\n",
        "\n",
        "# 6. GENERATE & SHOW\n",
        "imgs = G.predict(tf.random.normal([25, 100]), verbose=0)\n",
        "imgs = (imgs + 1) / 2  # Scale to [0, 1]\n",
        "\n",
        "fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(imgs[i].reshape(28, 28), cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIuEUTBFHxTw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO46gS+IxmDIZgi9Ll93+41",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}